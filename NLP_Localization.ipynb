{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Localization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-ooJKthW6LW",
        "colab_type": "text"
      },
      "source": [
        "# Solving localization problems using word vectors\n",
        "\n",
        "---\n",
        "\n",
        "> ##### Using NLP word vectors in a novel way to solve the problem of localization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LQJ3QYXfSTi",
        "colab_type": "text"
      },
      "source": [
        "### >> Problem Statement:\n",
        "---\n",
        "###### A sample third class (grade) math question in their question bank looks like this —\n",
        "\n",
        "> *_Frank lives in San Francisco and Elizabeth lives in Los Angeles. If the flight time is 2 hrs when will Elizabeth reach Frank if she starts at 8am in the morning?_*\n",
        "\n",
        "###### The same question if you want to write it in Indian books.\n",
        "> *_Sanjay Verma lives in Bangalore and Rekha lives in Mumbai. If the flight time is 2 hrs when will Rekha reach Sanjay Verma if she starts at 8am in the morning?_*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkMrHiIId4GK",
        "colab_type": "text"
      },
      "source": [
        "Before we start it's really important to know some terms like Word Embeddings, Word2Vec.\n",
        "\n",
        "## >> King - Man + Woman = Queen\n",
        "---\n",
        "We humans can easily understand the relationship or similarity between words, but it becomes a problem when it comes to Machines. How will you make a machine to understand the similarity between words?\n",
        "\n",
        "For a computer to perform any **reasoning** on words, we need to represent words numerically as vectors of numbers termed **embeddings**.\n",
        "\n",
        "Intuitively, where words are similar in some respect, that can be reflected by certain values in their embeddings being similar.\n",
        "\n",
        "##### Algorithms:\n",
        "* Word2Vec\n",
        "* Glove\n",
        "\n",
        "These algorithms learn word embeddings by extracting info from huge text sources such as Wikipedia.\n",
        "\n",
        "So you know, analogies like \n",
        "\"man is to king as woman is to ...?\" or \"Paris is to France as Rome is to ...?\",\n",
        "can often be solved simply by adding and subtracting embeddings.\n",
        "\n",
        "![Image1](https://blog.acolyer.org/wp-content/uploads/2016/04/word2vec-king-queen-vectors.png)\n",
        "\n",
        "### The result of the vector composition King – Man + Woman = ?\n",
        "\n",
        "![Image2](https://blog.acolyer.org/wp-content/uploads/2016/04/word2vec-king-queen-composition.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBO0TcqqsHp4",
        "colab_type": "text"
      },
      "source": [
        "So here, we will be solving the localization problem, but what is localization?\n",
        "\n",
        ">  _**Localization** is the general concept of adopting a product or idea to a different country or region respecting local norms, customs, and any other preferences. The goal is to resonate with the target audience for whom the content is localized._\n",
        "\n",
        "#### In simple terms, this conversion is basically localization.\n",
        "> *_Frank lives in San Francisco and Elizabeth lives in Los Angeles. If the flight time is 2 hrs when will Elizabeth reach Frank if she starts at 8am in the morning?_*\n",
        "\n",
        "> *_Sanjay Verma lives in Bangalore and Rekha lives in Mumbai. If the flight time is 2 hrs when will Rekha reach Sanjay Verma if she starts at 8am in the morning?_*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YARipx3KsXnQ",
        "colab_type": "text"
      },
      "source": [
        "## >> Let's Approach the problem:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rRV8Yl_w_Oi",
        "colab_type": "text"
      },
      "source": [
        "Now let’s look at how we can localize our original USA math question to the Indian context.\n",
        "\n",
        "> **Frank** lives in **San Francisco** and **Elizabeth** lives in **Los Angeles**. If the flight time is 2 hrs when will **Elizabeth** reach **Frank** if she starts at 8am in the morning?\n",
        "\n",
        "**Goal:** The goal here is, first find which words needs to be localized and then do it.\n",
        "\n",
        "---\n",
        "###### How to find that?\n",
        "> We will use one library named as **Spacy**. It is free, open-source library for advanced Natural Language Processing (NLP) in Python.\n",
        "\n",
        "---\n",
        "![7bf65640.png](https://miro.medium.com/max/875/1*EgZzlN3IdU6Q7Js7p6P7WA.png)\n",
        "\n",
        "**Step 1:** You see those highlights, Person, GPE, Time. Those are named entities and we will use  **Spacy Named Entity Recognition** to achieve this. \n",
        "\n",
        "\n",
        "**Step-2:** Filter named entities that are irrelevant. For example entities like numbers (cardinal) and time doesn’t need localization in our case.\n",
        "\n",
        "**Step-3:** Now comes the most interesting part. We will use the King-Man + Woman = Queen framework to convert each of the entities.\n",
        "\n",
        "* **Frank** - USA + India = Sanjay Verma\n",
        "* **San Franciso** - USA + India = Bangalore\n",
        "* **Elizabeth** - USA + India = Rekha\n",
        "* **Los Angeles** - USA + India = Mumbai\n",
        "\n",
        "**Step-4:** We go back and change the entities with their replacements to get\n",
        "\n",
        "> **Sanjay Verma** lives in **Bangalore** and **Rekha** lives in **Mumbai**. If the flight time is 2 hrs when will **Rekha** reach **Sanjay Verma** if she starts at 8am in the morning?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8T3WnFsxz10",
        "colab_type": "text"
      },
      "source": [
        "### >> Let's Code it out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLQqxksnx9_G",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Extract entities that need to be localized\n",
        "Example 1 focuses on an example that it completely automated and needs no manual intervention."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtUqjA-ax3J_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy import displacy\n",
        "from spacy.tokens import Span\n",
        "nlp = spacy.load(\"en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nflTv8U-0Nen",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9d64574e-72ff-41d4-c715-b2c6eea35706"
      },
      "source": [
        "original_input = \"Frank lives in San Francisco and Elizabeth lives in Los Angeles. If the flight time is 2 hrs when will Elizabeth reach Frank if she starts at 8am in the morning?\"\n",
        "processed_input_text=nlp(original_input)\n",
        "\n",
        "keyword_set = set()\n",
        "entity_mapping = []\n",
        "for token in processed_input_text.ents:\n",
        "    if token.text not in keyword_set:\n",
        "      keyword_set.add(token.text )\n",
        "      entity_mapping.append((token.text,token.label_))\n",
        "\n",
        "print (entity_mapping)\n",
        "\n",
        "# Display the entities\n",
        "displacy.render(processed_input_text, style='ent', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Frank', 'PERSON'), ('San Francisco', 'GPE'), ('Elizabeth', 'PERSON'), ('Los Angeles', 'GPE'), ('2', 'CARDINAL'), ('8am in the morning', 'TIME')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Frank\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " lives in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    San Francisco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Elizabeth\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " lives in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Los Angeles\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". If the flight time is \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " hrs when will \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Elizabeth\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " reach \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Frank\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " if she starts at \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    8am in the morning\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              "?</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUvw5RngH4-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4ecb2c9-147c-430e-b47e-2f7849651177"
      },
      "source": [
        "# Now all entities cannot be localized. Example no need to localize numbers. So keep only relevant entities that need to be localized.\n",
        "keep_entities_list = ['PERSON','GPE','FAC','ORG','PRODUCT','NORP','MONEY','LOC','WORK_OF_ART','LAW','LANGUAGE','QUANTITY']\n",
        "finalized_entity_mapping = {}\n",
        "for ent in entity_mapping:\n",
        "  if ent[1] in keep_entities_list:\n",
        "    finalized_entity_mapping[ent[0]] = []\n",
        "\n",
        "print (finalized_entity_mapping)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Frank': [], 'San Francisco': [], 'Elizabeth': [], 'Los Angeles': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwfSODnVIlgk",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Initialize the Google news word vectors from Gensim and perform localization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uxoR61WInrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "2fec2f97-f3ab-44d2-9830-d285ab31533a"
      },
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"word2vec-google-news-300\") \n",
        "word_vectors = model.wv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga3kZ-yoI1i8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "f3486504-df9c-4f9d-fd0e-ad708d8c1ed7"
      },
      "source": [
        "Origin_country='USA' \n",
        "Target_country='India'\n",
        "\n",
        "final_mapping ={}\n",
        "\n",
        "for word in finalized_entity_mapping: \n",
        "  word = word.strip()\n",
        "  word = word.replace(\" \",\"_\")\n",
        "  try:\n",
        "    similar_words_list= model.most_similar(positive=[Target_country,word],negative=[Origin_country],topn=10)\n",
        "    # Remove the scores for the retrieved choices\n",
        "    similar_words_list = [choices[0].replace(\"_\",\" \") for choices in similar_words_list ]\n",
        "    final_mapping[word.replace(\"_\",\" \")] = similar_words_list\n",
        "  except:\n",
        "    similar_words_list = []\n",
        "    print (\" Fetching similar words failed for \",word)\n",
        "  print (word,\" -- Replacement suggestions -- \",similar_words_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Frank  -- Replacement suggestions --  ['Sanjay Verma', 'Sabyasachi Sen', 'JK Jain', 'Sunil Chauhan', 'Don', 'Sudip', 'Ajay Shankar', 'Robert', 'V. Srinivasan', 'Kanwar Sain']\n",
            "San_Francisco  -- Replacement suggestions --  ['Bangalore', 'Kolkata', 'Mumbai', 'Chennai', 'Delhi', 'Hyderabad', 'Calcutta', 'San Franciso', 'Bombay', 'Bengaluru']\n",
            "Elizabeth  -- Replacement suggestions --  ['Rekha', 'Nandita', 'Meera', 'Margaret', 'Katharine', 'Bhagirath', 'Monica', 'Lakshmi', 'Manisha', 'Anita']\n",
            "Los_Angeles  -- Replacement suggestions --  ['Mumbai', 'Los Angles', 'Kolkata', 'Chennai', 'Bangalore', 'LA', 'Delhi', 'Hyderabad', 'Ahmedabad', 'Calcutta']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNvWw81hLgWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "7499f11c-1767-44f2-bc8c-6925d4130cf6"
      },
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "#  Here localization is performed assuming the correct choice is returned first.\n",
        "#  Elizabeth  -- Replacement suggestions --  ['Rekha', 'Nandita', 'Meera', 'Margaret', 'Katharine', 'Bhagirath', 'Monica', 'Lakshmi', 'Manisha', 'Anita']\n",
        "#  Example Elizabeth  is replaced with Rekha.\n",
        "\n",
        "#  This function is used to bolden the relevant entities that are changed.\n",
        "def prepare_string(sentence,mapping,orig=True):\n",
        "  if orig:\n",
        "    for k in mapping:\n",
        "      sentence = sentence.replace(k,\"**\"+k+\"**\")\n",
        "  else:\n",
        "    for k in mapping:\n",
        "      sentence = sentence.replace(mapping[k][0],\"**\"+mapping[k][0]+\"**\")\n",
        "\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def localize(sentence,mapping):\n",
        "  for k in mapping:\n",
        "    sentence = sentence.replace(k,mapping[k][0])\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "\n",
        "\n",
        "print('Original Sentence:')\n",
        "printmd(prepare_string(original_input,final_mapping))\n",
        "\n",
        "localized_string =  localize(original_input,final_mapping)\n",
        "\n",
        "print('\\nLocalized Sentence:')\n",
        "printmd(prepare_string(localized_string,final_mapping,orig=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**Frank** lives in **San Francisco** and **Elizabeth** lives in **Los Angeles**. If the flight time is 2 hrs when will **Elizabeth** reach **Frank** if she starts at 8am in the morning?",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Localized Sentence:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**Sanjay Verma** lives in **Bangalore** and **Rekha** lives in **Mumbai**. If the flight time is 2 hrs when will **Rekha** reach **Sanjay Verma** if she starts at 8am in the morning?",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}